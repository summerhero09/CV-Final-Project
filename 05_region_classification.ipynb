{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a16989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TASKS = {\n",
    "    \"eyes\": [\"Narrow_Eyes\", \"Arched_Eyebrows\"],\n",
    "    \"nose\": [\"Big_Nose\", \"Pointy_Nose\"],\n",
    "    \"lips\": [\"Big_Lips\"],\n",
    "    \"face\": [\"Oval_Face\", \"Pale_Skin\"],\n",
    "    \"cheeks\": [\"High_Cheekbones\", \"Rosy_Cheeks\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f68c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_binary_task(name, show_pca=True):\n",
    "    X = np.load(f\"{name}_embeddings.npy\")\n",
    "    y = np.load(f\"{name}_labels.npy\")\n",
    "\n",
    "    if len(np.unique(y)) < 2:\n",
    "        print(\"Only one class present â€” skipping.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"Labels:\", np.unique(y, return_counts=True))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(max_iter=3000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(\n",
    "    clf,\n",
    "    MODEL_DIR / f\"{name}_classifier.joblib\"\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    if show_pca:\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        for label in [0, 1]:\n",
    "            idx = y == label\n",
    "            plt.scatter(\n",
    "                X_pca[idx, 0],\n",
    "                X_pca[idx, 1],\n",
    "                label=\"Positive\" if label == 1 else \"Negative\",\n",
    "                alpha=0.5\n",
    "            )\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title(f\"{name} Embeddings (PCA)\")\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.show()\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb908de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eyes_Narrow_Eyes\n",
      "X shape: (988, 512)\n",
      "Labels: (array([0, 1]), array([500, 488]))\n",
      "Accuracy: 1.0\n",
      "Confusion matrix:\n",
      "[[50  0]\n",
      " [ 0 49]]\n",
      "\n",
      "eyes_Arched_Eyebrows\n",
      "X shape: (988, 512)\n",
      "Labels: (array([0, 1]), array([488, 500]))\n",
      "Accuracy: 0.98989898989899\n",
      "Confusion matrix:\n",
      "[[49  0]\n",
      " [ 1 49]]\n",
      "\n",
      "nose_Big_Nose\n",
      "X shape: (21951, 512)\n",
      "Labels: (array([0, 1]), array([11499, 10452]))\n",
      "Accuracy: 0.7691256830601093\n",
      "Confusion matrix:\n",
      "[[928 222]\n",
      " [285 761]]\n",
      "\n",
      "nose_Pointy_Nose\n",
      "X shape: (21951, 512)\n",
      "Labels: (array([0, 1]), array([10452, 11499]))\n",
      "Accuracy: 0.76183970856102\n",
      "Confusion matrix:\n",
      "[[754 292]\n",
      " [231 919]]\n",
      "Skipping lips_Big_Lips: [Errno 2] No such file or directory: 'lips_Big_Lips_embeddings.npy'\n",
      "\n",
      "face_Oval_Face\n",
      "X shape: (1447, 512)\n",
      "Labels: (array([0, 1]), array([949, 498]))\n",
      "Accuracy: 0.6758620689655173\n",
      "Confusion matrix:\n",
      "[[73 22]\n",
      " [25 25]]\n",
      "\n",
      "face_Pale_Skin\n",
      "X shape: (1447, 512)\n",
      "Labels: (array([0, 1]), array([955, 492]))\n",
      "Accuracy: 0.7793103448275862\n",
      "Confusion matrix:\n",
      "[[80 16]\n",
      " [16 33]]\n",
      "\n",
      "cheeks_High_Cheekbones\n",
      "X shape: (995, 512)\n",
      "Labels: (array([0, 1]), array([500, 495]))\n",
      "Accuracy: 0.66\n",
      "Confusion matrix:\n",
      "[[35 15]\n",
      " [19 31]]\n",
      "\n",
      "cheeks_Rosy_Cheeks\n",
      "X shape: (995, 512)\n",
      "Labels: (array([0, 1]), array([495, 500]))\n",
      "Accuracy: 0.6\n",
      "Confusion matrix:\n",
      "[[28 22]\n",
      " [18 32]]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for region, attrs in TASKS.items():\n",
    "    for attr in attrs:\n",
    "        task_name = f\"{region}_{attr}\"\n",
    "        try:\n",
    "            acc = evaluate_binary_task(task_name, show_pca=False)\n",
    "            results[task_name] = acc\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {task_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053cf1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cosine Similarity Results ===\n",
      "face_Pale_Skin\n",
      "  Same-label (+/+): 0.802\n",
      "  Same-label (-/-): 0.770\n",
      "  Cross-label (+/-): 0.770\n",
      "\n",
      "face_Oval_Face\n",
      "  Same-label (+/+): 0.804\n",
      "  Same-label (-/-): 0.764\n",
      "  Cross-label (+/-): 0.775\n",
      "\n",
      "cheeks_Rosy_Cheeks\n",
      "  Same-label (+/+): 0.850\n",
      "  Same-label (-/-): 0.809\n",
      "  Cross-label (+/-): 0.822\n",
      "\n",
      "eyes_Narrow_Eyes\n",
      "  Same-label (+/+): 0.798\n",
      "  Same-label (-/-): 0.855\n",
      "  Cross-label (+/-): 0.795\n",
      "\n",
      "cheeks_High_Cheekbones\n",
      "  Same-label (+/+): 0.809\n",
      "  Same-label (-/-): 0.850\n",
      "  Cross-label (+/-): 0.822\n",
      "\n",
      "eyes_Arched_Eyebrows\n",
      "  Same-label (+/+): 0.855\n",
      "  Same-label (-/-): 0.798\n",
      "  Cross-label (+/-): 0.795\n",
      "\n",
      "nose_Big_Nose\n",
      "  Same-label (+/+): 0.811\n",
      "  Same-label (-/-): 0.844\n",
      "  Cross-label (+/-): 0.818\n",
      "\n",
      "nose_Pointy_Nose\n",
      "  Same-label (+/+): 0.844\n",
      "  Same-label (-/-): 0.811\n",
      "  Cross-label (+/-): 0.818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def evaluate_cosine_similarity(embeddings_dir=\"embeddings\"):\n",
    "    results = []\n",
    "\n",
    "    for fname in os.listdir(embeddings_dir):\n",
    "        if not fname.endswith(\"_embeddings.npy\"):\n",
    "            continue\n",
    "\n",
    "        prefix = fname.replace(\"_embeddings.npy\", \"\")\n",
    "        emb_path = os.path.join(embeddings_dir, fname)\n",
    "        label_path = os.path.join(embeddings_dir, prefix + \"_labels.npy\")\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Missing labels for {prefix}, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Load data\n",
    "        X = np.load(emb_path)\n",
    "        y = np.load(label_path)\n",
    "\n",
    "        # Safety checks\n",
    "        if len(np.unique(y)) < 2:\n",
    "            print(f\"Skipping {prefix} (single class)\")\n",
    "            continue\n",
    "\n",
    "        X_pos = X[y == 1]\n",
    "        X_neg = X[y == 0]\n",
    "\n",
    "        # Skip if too few samples\n",
    "        if len(X_pos) < 2 or len(X_neg) < 2:\n",
    "            print(f\"Skipping {prefix} (not enough samples)\")\n",
    "            continue\n",
    "\n",
    "        # Cosine similarities\n",
    "        sim_pos = cosine_similarity(X_pos)\n",
    "        sim_neg = cosine_similarity(X_neg)\n",
    "        sim_cross = cosine_similarity(X_pos, X_neg)\n",
    "\n",
    "        # Remove self-similarity (diagonal)\n",
    "        pos_mean = sim_pos[np.triu_indices_from(sim_pos, k=1)].mean()\n",
    "        neg_mean = sim_neg[np.triu_indices_from(sim_neg, k=1)].mean()\n",
    "        cross_mean = sim_cross.mean()\n",
    "\n",
    "        results.append((prefix, pos_mean, neg_mean, cross_mean))\n",
    "\n",
    "    # Print nicely\n",
    "    print(\"\\n=== Cosine Similarity Results ===\")\n",
    "    for prefix, pos, neg, cross in results:\n",
    "        print(f\"{prefix}\")\n",
    "        print(f\"  Same-label (+/+): {pos:.3f}\")\n",
    "        print(f\"  Same-label (-/-): {neg:.3f}\")\n",
    "        print(f\"  Cross-label (+/-): {cross:.3f}\")\n",
    "        print()\n",
    "\n",
    "    return results\n",
    "\n",
    "results = evaluate_cosine_similarity(\"embeddings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
